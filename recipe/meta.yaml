{% set name = "polars" %}
{% set version = "0.20.18" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  - url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/polars-{{ version }}.tar.gz
    sha256: 8a321cbdbb459e3c0cc1af2ce6ac930d0d3b5ccbeb2dd3e4237ad07d487fd290

build:
  number: 0
  # supporting py3.8+
  skip: True  # [py<38]
  # no rust nightly compiler for s390x
  skip: true  # [s390x]
  # skipping windows because missing maturin >=1.3.2 and since win is not a priority for SF
  skip: true  # [win]

requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('rust') }}
    - python
    - posix   # [win]
    - cmake
    - make    # [unix]
    - cargo-bundle-licenses
  host:
    - python
    - pip
    - maturin >=1.3.2
  run:
    - python
    - numpy >=1.16.0

# skipping test_delta because of missing fastexcel and ezodf
{% set tests_modules_to_ignore = " --ignore=py-polars/tests/unit/io/test_spreadsheet.py" %}
# skipping test_delta because of missing adbc_driver_sqlite
{% set tests_modules_to_ignore = tests_modules_to_ignore + " --ignore=py-polars/tests/unit/io/database/test_read.py --ignore=py-polars/tests/unit/io/database/test_write.py" %}
# skipping test_delta because of some authentication problem (403 forbidden)
{% set tests_modules_to_ignore = tests_modules_to_ignore + " --ignore=py-polars/tests/unit/io/cloud/test_aws.py" %}

# skipping problematic tests without clear troubleshooting
{% set tests_to_skip = "test_namespace_warning_on_override or test_cse_expr_selection_context or test_extension" %}
{% set tests_to_skip = tests_to_skip + " or test_from_dataframe_pandas_parametric or test_from_dataframe_pandas_zero_copy_parametric" %}
{% set tests_to_skip = tests_to_skip + " or test_from_dataframe_pandas_timestamp_ns or test_streaming_sort" %}

# skipping tests that fail on py3.8 and osx most likely because of incorrect handling of underlying types in pandas.DataFrames
# (not related to polars)
{% set tests_to_skip = tests_to_skip + " or test_from_dataframe_pandas_native_parametric or test_from_dataframe_pandas_native_zero_copy_parametric" %}  # [osx and py==38]
{% set tests_to_skip = tests_to_skip + " or test_to_dataframe_pandas_boolean_subchunks or test_from_pandas_index or test_to_pandas" %}                  # [osx and py==38]

# skipping tests that fail on prefect because of missing avro files
{% set tests_to_skip = tests_to_skip + " or test_scan_iceberg_plain or test_scan_iceberg_filter_on_partition or test_scan_iceberg_filter_on_column" %}

# skipping this import test, because it is an upstream issue as documented in https://github.com/pola-rs/polars/issues/14442
{% set tests_to_skip = tests_to_skip + " or test_polars_import" %}

test:
  source_files:
    - py-polars/tests
  imports:
    - polars
  commands:
    - pip check
    - python -c "from polars import DataFrame"
    - conda install -c conda-forge -y deltalake pyiceberg xlsx2csv  # [py<312]
    - pytest py-polars/tests -k "not ({{ tests_to_skip }})" {{ tests_modules_to_ignore }}  # [py<312]
  requires:
    - pip
    - pytest
    - hypothesis >=6.97.4
    - pyarrow
    - pandas
    - boto3
    - sqlalchemy
    - moto
    - pydantic
    - zstandard
    - matplotlib
    - nest-asyncio
    - cloudpickle
    - fsspec
    - gevent
    - openpyxl >=3.0.0
    - pandas
    - hvplot >=0.9.1
    - pyarrow >=7.0.0
    - pydantic >=2.0.0
    - pyxlsb >=1.0  # [py<312]
    - sqlalchemy
    - backports.zoneinfo  # [py<39]
    - tzdata  # [win]
    - xlsxwriter
    - aiosqlite
    # from conda-forge
    # - deltalake
    # - pyiceberg
    # - xlsx2csv
about:
  home: https://github.com/pola-rs/polars
  license: MIT
  license_family: MIT
  license_file:
    - LICENSE
    - THIRDPARTY.yml
  summary: Polars is a blazingly fast DataFrames library implemented in Rust using Apache Arrow(2) as memory model.
  description: |
    Polars is a blazingly fast DataFrame library for manipulating structured data. The core is written in Rust, and
    available for Python, R and NodeJS.
    Key features:
      * Fast: Written from scratch in Rust, designed close to the machine and without external dependencies.
      * I/O: First class support for all common data storage layers: local, cloud storage & databases.
      * Intuitive API: Write your queries the way they were intended. Polars, internally, will determine the most efficient way to execute using its query optimizer.
      * Out of Core: The streaming API allows you to process your results without requiring all your data to be in memory at the same time
      * Parallel: Utilises the power of your machine by dividing the workload among the available CPU cores without any additional configuration.
      * Vectorized Query Engine: Using Apache Arrow, a columnar data format, to process your queries in a vectorized manner and SIMD to optimize CPU usage.
  doc_url: https://pola-rs.github.io/polars-book/user-guide/index.html
  dev_url: https://github.com/pola-rs/polars

extra:
  recipe-maintainers:
    - borchero
    - Maxyme
    - timkpaine
    - ritchie46
    - sugatoray
    - xhochy
    - dhirschfeld
    - pavelzw
    - '0xbe7a'
  skip-lints:
    - missing_wheel
